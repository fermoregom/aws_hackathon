# requirements.txt
"""
streamlit>=1.28.0
langchain>=0.1.0
langchain-aws>=0.1.0
langchain-community>=0.0.20
boto3>=1.28.0
python-dotenv>=1.0.0
"""

# chatbot_app.py
import streamlit as st
import boto3
import os
from dotenv import load_dotenv
from typing import List, Dict, Any, Optional
from datetime import datetime
import json

# LangChain imports
from langchain_aws import ChatBedrockConverse
from langchain.memory import ConversationBufferWindowMemory
from langchain.schema import BaseMessage, HumanMessage, AIMessage, SystemMessage
from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain.callbacks.base import BaseCallbackHandler
from langchain.schema.output import LLMResult

# Cargar variables de entorno
load_dotenv()

# Configuraci√≥n de Streamlit
st.set_page_config(
    page_title="ü§ñ Chatbot Nova Lite",
    page_icon="üöÄ",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Callback para mostrar streaming en tiempo real
class StreamlitCallbackHandler(BaseCallbackHandler):
    """Callback handler para mostrar respuestas en streaming"""
    
    def __init__(self, container):
        self.container = container
        self.text = ""
    
    def on_llm_new_token(self, token: str, **kwargs) -> None:
        self.text += token
        self.container.markdown(self.text + "‚ñå")
    
    def on_llm_end(self, response: LLMResult, **kwargs) -> None:
        self.container.markdown(self.text)

def create_bedrock_llm(region_name="us-east-2", model_id="us.amazon.nova-lite-v1:0"):
    """Crear instancia de Nova Lite a trav√©s de Bedrock"""
    return ChatBedrockConverse(
        client=boto3.client(
            service_name='bedrock-runtime',
            region_name=region_name,
            aws_access_key_id=os.getenv("AWS_ACCESS_KEY_ID"),
            aws_secret_access_key=os.getenv("AWS_SECRET_ACCESS_KEY"),
            config=boto3.session.Config(
                read_timeout=300,  # 5 minutos
                connect_timeout=60,  # 1 minuto
                retries={'max_attempts': 2}
            )
        ),
        model=model_id,
        max_tokens=7000,
        temperature=0.15,
        top_p=0.9,
        region_name=region_name
    )

class NovaLiteChatbot:
    """Clase principal del chatbot usando AWS Nova Lite"""
    
    def __init__(self, region_name: str = "us-east-2", model_id: str = "us.amazon.nova-lite-v1:0", 
                 memory_size: int = 10, system_prompt: str = None):
        """
        Inicializar el chatbot
        
        Args:
            region_name: Regi√≥n de AWS
            model_id: ID del modelo Nova Lite
            memory_size: Cantidad de mensajes a recordar
            system_prompt: Prompt del sistema personalizado
        """
        self.region_name = region_name
        self.model_id = model_id
        self.memory_size = memory_size
        
        # Crear instancia del modelo
        self.llm = create_bedrock_llm(region_name, model_id)
        
        # Configurar memoria conversacional
        self.memory = ConversationBufferWindowMemory(
            k=memory_size,
            return_messages=True
        )
        
        # Sistema de prompts
        self.system_prompt = system_prompt or self._default_system_prompt()
        self.prompt_template = self._create_prompt_template()
        
        # Estad√≠sticas
        self.stats = {
            "total_messages": 0,
            "total_tokens_estimated": 0,
            "session_start": datetime.now(),
            "last_interaction": None
        }
    
    def _default_system_prompt(self) -> str:
        """Prompt del sistema por defecto"""
        return """Eres un asistente de IA amigable, √∫til y conocedor. Tu nombre es Nova Assistant.

Caracter√≠sticas de tu personalidad:
- Eres amigable, profesional y emp√°tico
- Respondes de manera clara y concisa
- Puedes ayudar con una amplia variedad de temas
- Si no sabes algo, lo admites honestamente
- Mantienes un tono conversacional natural
- Eres proactivo en ofrecer ayuda adicional

Instrucciones:
- Responde en el idioma que te hablen
- Proporciona respuestas estructuradas cuando sea apropiado
- Si la pregunta es ambigua, pide aclaraciones
- Mant√©n las respuestas enfocadas y relevantes
- Usa ejemplos cuando ayuden a explicar conceptos

Recuerda: Eres capaz, servicial y siempre buscas ser lo m√°s √∫til posible para el usuario."""
    
    def _create_prompt_template(self) -> ChatPromptTemplate:
        """Crear template de prompt con memoria"""
        return ChatPromptTemplate.from_messages([
            ("system", self.system_prompt),
            MessagesPlaceholder(variable_name="history"),
            ("human", "{input}")
        ])
    
    def chat(self, user_input: str, callback_handler: Optional[BaseCallbackHandler] = None) -> Dict[str, Any]:
        """
        Procesar un mensaje del usuario
        
        Args:
            user_input: Mensaje del usuario
            callback_handler: Handler para streaming (opcional)
            
        Returns:
            Diccionario con la respuesta y metadata
        """
        try:
            start_time = datetime.now()
            
            # Configurar callbacks
            callbacks = [callback_handler] if callback_handler else []
            
            # Obtener historial de mensajes
            history = self.memory.chat_memory.messages
            
            # Crear el prompt completo
            formatted_prompt = self.prompt_template.format_messages(
                input=user_input,
                history=history
            )
            
            # Llamar al LLM directamente
            response = self.llm.invoke(formatted_prompt, config={"callbacks": callbacks})
            
            # Guardar en memoria
            self.memory.chat_memory.add_user_message(user_input)
            self.memory.chat_memory.add_ai_message(response.content)
            
            end_time = datetime.now()
            processing_time = (end_time - start_time).total_seconds()
            
            # Actualizar estad√≠sticas
            self.stats["total_messages"] += 1
            self.stats["total_tokens_estimated"] += len(user_input.split()) + len(response.content.split())
            self.stats["last_interaction"] = end_time
            
            return {
                "response": response.content,
                "processing_time": processing_time,
                "timestamp": end_time.isoformat(),
                "user_input": user_input,
                "success": True,
                "error": None
            }
            
        except Exception as e:
            error_msg = f"Error al procesar mensaje: {str(e)}"
            
            return {
                "response": "Lo siento, hubo un error al procesar tu mensaje. Por favor, intenta de nuevo.",
                "processing_time": 0,
                "timestamp": datetime.now().isoformat(),
                "user_input": user_input,
                "success": False,
                "error": error_msg
            }
    
    def get_conversation_history(self) -> List[BaseMessage]:
        """Obtener historial de conversaci√≥n"""
        return self.memory.chat_memory.messages
    
    def clear_memory(self):
        """Limpiar memoria conversacional"""
        self.memory.clear()
        self.stats["total_messages"] = 0
        self.stats["total_tokens_estimated"] = 0
        self.stats["session_start"] = datetime.now()
    
    def get_stats(self) -> Dict[str, Any]:
        """Obtener estad√≠sticas de la sesi√≥n"""
        current_time = datetime.now()
        session_duration = (current_time - self.stats["session_start"]).total_seconds()
        
        return {
            **self.stats,
            "session_duration_minutes": round(session_duration / 60, 2),
            "avg_tokens_per_message": (
                self.stats["total_tokens_estimated"] / max(self.stats["total_messages"], 1)
            ),
            "model_info": {
                "model_id": self.model_id,
                "region": self.region_name,
                "memory_size": self.memory_size
            }
        }
    
    def export_conversation(self) -> str:
        """Exportar conversaci√≥n como JSON"""
        history = []
        for message in self.get_conversation_history():
            history.append({
                "type": message.__class__.__name__,
                "content": message.content,
                "timestamp": datetime.now().isoformat()
            })
        
        export_data = {
            "conversation": history,
            "stats": self.get_stats(),
            "export_timestamp": datetime.now().isoformat()
        }
        
        return json.dumps(export_data, indent=2, ensure_ascii=False)

# Funciones de la interfaz Streamlit
def initialize_chatbot() -> NovaLiteChatbot:
    """Inicializar el chatbot con configuraci√≥n personalizada"""
    
    # Configuraci√≥n desde sidebar
    with st.sidebar:
        st.header("‚öôÔ∏è Configuraci√≥n del Modelo")
        
        region = st.selectbox(
            "Regi√≥n AWS",
            ["us-east-2", "us-east-1", "us-west-2", "eu-west-1"],
            index=0
        )
        
        model_options = [
            "us.amazon.nova-lite-v1:0",
            "us.amazon.nova-micro-v1:0",
            "us.amazon.nova-pro-v1:0"
        ]
        
        model_id = st.selectbox(
            "Modelo Nova",
            model_options,
            index=0
        )
        
        memory_size = st.slider(
            "Memoria conversacional",
            min_value=5,
            max_value=50,
            value=10,
            help="Cantidad de mensajes anteriores a recordar"
        )
        
        # Prompt del sistema personalizado
        st.header("üé≠ Personalizaci√≥n")
        custom_prompt = st.text_area(
            "Prompt del sistema (opcional)",
            placeholder="Personaliza el comportamiento del asistente...",
            height=100
        )
    
    return NovaLiteChatbot(
        region_name=region,
        model_id=model_id,
        memory_size=memory_size,
        system_prompt=custom_prompt if custom_prompt else None
    )

def display_chat_interface(chatbot: NovaLiteChatbot):
    """Mostrar interfaz principal del chat"""
    
    # T√≠tulo y descripci√≥n
    st.title("ü§ñ Nova Lite Assistant")
    st.markdown("*Chatbot inteligente powered by AWS Bedrock Nova Lite*")
    
    # Verificar credenciales AWS
    if not (os.getenv("AWS_ACCESS_KEY_ID") and os.getenv("AWS_SECRET_ACCESS_KEY")):
        st.error("‚ùå Por favor configura tus credenciales AWS en las variables de entorno")
        st.info("Necesitas: AWS_ACCESS_KEY_ID y AWS_SECRET_ACCESS_KEY")
        return
    
    # Inicializar historial en session state
    if 'chat_history' not in st.session_state:
        st.session_state.chat_history = []
    
    # Mostrar estad√≠sticas en la sidebar
    with st.sidebar:
        st.header("üìä Estad√≠sticas")
        stats = chatbot.get_stats()
        
        col1, col2 = st.columns(2)
        with col1:
            st.metric("Mensajes", stats["total_messages"])
            st.metric("Duraci√≥n (min)", stats["session_duration_minutes"])
        with col2:
            st.metric("Tokens aprox.", stats["total_tokens_estimated"])
            st.metric("Promedio tokens", round(stats["avg_tokens_per_message"]))
        
        # Botones de control
        st.header("üõ†Ô∏è Controles")
        
        if st.button("üóëÔ∏è Limpiar conversaci√≥n"):
            chatbot.clear_memory()
            st.session_state.chat_history = []
            st.rerun()
        
        if st.button("üíæ Exportar conversaci√≥n"):
            export_data = chatbot.export_conversation()
            st.download_button(
                label="üì• Descargar JSON",
                data=export_data,
                file_name=f"conversacion_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json",
                mime="application/json"
            )
    
    # √Årea principal del chat
    st.header("üí¨ Conversaci√≥n")
    
    # Container para el historial
    chat_container = st.container()
    
    # Mostrar historial
    with chat_container:
        for i, (user_msg, bot_response, metadata) in enumerate(st.session_state.chat_history):
            # Mensaje del usuario
            with st.chat_message("user"):
                st.write(user_msg)
            
            # Respuesta del bot
            with st.chat_message("assistant"):
                st.write(bot_response)
                
                # Mostrar metadata en expander
                with st.expander("‚ÑπÔ∏è Detalles"):
                    col1, col2, col3 = st.columns(3)
                    with col1:
                        st.write(f"**Tiempo:** {metadata.get('processing_time', 0):.2f}s")
                    with col2:
                        st.write(f"**Estado:** {'‚úÖ' if metadata.get('success') else '‚ùå'}")
                    with col3:
                        st.write(f"**Timestamp:** {metadata.get('timestamp', '')[:19]}")
                    
                    if not metadata.get('success') and metadata.get('error'):
                        st.error(f"Error: {metadata['error']}")
    
    # Input para nuevo mensaje
    user_input = st.chat_input("Escribe tu mensaje aqu√≠...")
    
    if user_input:
        # Crear container para respuesta en streaming
        response_container = st.empty()
        
        # Mostrar mensaje del usuario inmediatamente
        with st.chat_message("user"):
            st.write(user_input)
        
        # Procesar respuesta con streaming
        with st.chat_message("assistant"):
            # Container para el streaming
            streaming_container = st.empty()
            
            # Crear callback handler para streaming
            callback_handler = StreamlitCallbackHandler(streaming_container)
            
            # Procesar mensaje
            with st.spinner("ü§î Pensando..."):
                result = chatbot.chat(user_input, callback_handler)
            
            # Agregar al historial
            st.session_state.chat_history.append((
                user_input,
                result["response"],
                result
            ))
        
        # Rerun para mostrar la conversaci√≥n actualizada
        st.rerun()

def display_examples():
    """Mostrar ejemplos de uso"""
    st.header("üí° Ejemplos de conversaci√≥n")
    
    examples = [
        "Expl√≠came qu√© es la inteligencia artificial",
        "¬øPuedes ayudarme a escribir un email profesional?",
        "¬øCu√°les son las mejores pr√°cticas para programar en Python?",
        "Necesito ideas para un proyecto de machine learning",
        "¬øC√≥mo puedo mejorar mi productividad en el trabajo?"
    ]
    
    for example in examples:
        if st.button(f"üí¨ {example}", key=f"example_{hash(example)}"):
            # Simular input del usuario
            st.session_state.example_input = example

def main():
    """Funci√≥n principal de la aplicaci√≥n"""
    
    try:
        # Inicializar chatbot
        if 'chatbot' not in st.session_state:
            st.session_state.chatbot = initialize_chatbot()
        
        # Tabs principales
        tab1, tab2, tab3 = st.tabs(["üí¨ Chat", "üí° Ejemplos", "üìñ Ayuda"])
        
        with tab1:
            display_chat_interface(st.session_state.chatbot)
        
        with tab2:
            display_examples()
        
        with tab3:
            st.header("üìñ Gu√≠a de uso")
            st.markdown("""
            ### üöÄ C√≥mo usar el chatbot:
            
            1. **Configuraci√≥n**: Ajusta el modelo y par√°metros en la barra lateral
            2. **Credenciales**: Aseg√∫rate de tener configuradas las variables de entorno AWS
            3. **Conversaci√≥n**: Escribe tu mensaje en el campo de texto inferior
            4. **Memoria**: El bot recuerda conversaciones anteriores seg√∫n la configuraci√≥n
            5. **Exportar**: Puedes descargar el historial de conversaci√≥n
            
            ### üîß Variables de entorno requeridas:
            ```
            AWS_ACCESS_KEY_ID=tu_access_key
            AWS_SECRET_ACCESS_KEY=tu_secret_key
            ```
            
            ### üìä Caracter√≠sticas:
            - ‚úÖ Memoria conversacional configurable
            - ‚úÖ Streaming de respuestas en tiempo real
            - ‚úÖ Estad√≠sticas de uso detalladas
            - ‚úÖ Exportaci√≥n de conversaciones
            - ‚úÖ M√∫ltiples modelos Nova disponibles
            - ‚úÖ Configuraci√≥n flexible de prompts
            """)
    
    except Exception as e:
        st.error(f"‚ùå Error al inicializar la aplicaci√≥n: {str(e)}")
        st.info("Verifica tu configuraci√≥n de AWS y las credenciales")

if __name__ == "__main__":
    main()
